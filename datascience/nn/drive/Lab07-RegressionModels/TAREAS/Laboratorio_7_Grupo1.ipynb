{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Laboratorio_7_Grupo1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gOZoEqAOvIBw"},"source":["# **50 Startups**"]},{"cell_type":"markdown","metadata":{"id":"oM6l8RfK8kMT"},"source":["ingrid Katherine Denisse Garcia Granados\r\n","\r\n","Sharon Anesveth Alvarado Maatens\r\n","\r\n","Marlon Daniel Tzorin Sagastume\r\n","\r\n","Roberto Lacayo"]},{"cell_type":"markdown","metadata":{"id":"PT_o6L8a459e"},"source":["# Simple Linear Regression"]},{"cell_type":"code","metadata":{"id":"2pNyx34nvAlR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613416718396,"user_tz":360,"elapsed":2526,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"8aaa597b-1881-459b-ceb1-662561d5be99"},"source":["# Importing the libraries\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import statsmodels.api as sm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dzBDDT5IwnDy"},"source":["# Importing the dataset\r\n","dataset = pd.read_csv('50_Startups.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, 4].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"LpMVdXV3xs_O","executionInfo":{"status":"ok","timestamp":1613416853517,"user_tz":360,"elapsed":902,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"75c121d8-0c2c-4c1f-eed6-37ffaa9a5c19"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>R&amp;D Spend</th>\n","      <th>Administration</th>\n","      <th>Marketing Spend</th>\n","      <th>State</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>165349.20</td>\n","      <td>136897.80</td>\n","      <td>471784.10</td>\n","      <td>New York</td>\n","      <td>192261.83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>162597.70</td>\n","      <td>151377.59</td>\n","      <td>443898.53</td>\n","      <td>California</td>\n","      <td>191792.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>153441.51</td>\n","      <td>101145.55</td>\n","      <td>407934.54</td>\n","      <td>Florida</td>\n","      <td>191050.39</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>144372.41</td>\n","      <td>118671.85</td>\n","      <td>383199.62</td>\n","      <td>New York</td>\n","      <td>182901.99</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>142107.34</td>\n","      <td>91391.77</td>\n","      <td>366168.42</td>\n","      <td>Florida</td>\n","      <td>166187.94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   R&D Spend  Administration  Marketing Spend       State     Profit\n","0  165349.20       136897.80        471784.10    New York  192261.83\n","1  162597.70       151377.59        443898.53  California  191792.06\n","2  153441.51       101145.55        407934.54     Florida  191050.39\n","3  144372.41       118671.85        383199.62    New York  182901.99\n","4  142107.34        91391.77        366168.42     Florida  166187.94"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"LniINIz7z37O"},"source":["# Encoding categorical data\r\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n","labelencoder = LabelEncoder()\r\n","X[:, 3] = labelencoder.fit_transform(X[:, 3])\r\n","onehotencoder = OneHotEncoder(categories='auto')\r\n","X = onehotencoder.fit_transform(X).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Z_PEncw2tXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613416935325,"user_tz":360,"elapsed":379,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"c98b8114-6d59-4497-b9de-a73d3057de70"},"source":["# Avoiding the Dummy Variable Trap\r\n","X = X[:, 1:]\r\n","print(X)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1. 0. 0. ... 0. 0. 1.]\n"," [1. 0. 0. ... 1. 1. 0.]\n"," [1. 0. 0. ... 1. 1. 0.]\n"," ...\n"," [1. 0. 0. ... 1. 1. 0.]\n"," [0. 1. 0. ... 0. 0. 1.]\n"," [1. 0. 0. ... 1. 1. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"T1iS1BEqynoG","executionInfo":{"status":"ok","timestamp":1613416958935,"user_tz":360,"elapsed":789,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"7f6a0d75-c1dc-460a-bc52-4f003617a5a5"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>R&amp;D Spend</th>\n","      <th>Administration</th>\n","      <th>Marketing Spend</th>\n","      <th>State</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>165349.20</td>\n","      <td>136897.80</td>\n","      <td>471784.10</td>\n","      <td>New York</td>\n","      <td>192261.83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>162597.70</td>\n","      <td>151377.59</td>\n","      <td>443898.53</td>\n","      <td>California</td>\n","      <td>191792.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>153441.51</td>\n","      <td>101145.55</td>\n","      <td>407934.54</td>\n","      <td>Florida</td>\n","      <td>191050.39</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>144372.41</td>\n","      <td>118671.85</td>\n","      <td>383199.62</td>\n","      <td>New York</td>\n","      <td>182901.99</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>142107.34</td>\n","      <td>91391.77</td>\n","      <td>366168.42</td>\n","      <td>Florida</td>\n","      <td>166187.94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   R&D Spend  Administration  Marketing Spend       State     Profit\n","0  165349.20       136897.80        471784.10    New York  192261.83\n","1  162597.70       151377.59        443898.53  California  191792.06\n","2  153441.51       101145.55        407934.54     Florida  191050.39\n","3  144372.41       118671.85        383199.62    New York  182901.99\n","4  142107.34        91391.77        366168.42     Florida  166187.94"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"qLbb9UILxy5i"},"source":["# Splitting the dataset into the Training set and Test set\r\n","from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"H8ATysKux_4N","executionInfo":{"status":"ok","timestamp":1613417015783,"user_tz":360,"elapsed":448,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"c7ac6628-cccf-4188-e230-98b03485c272"},"source":["# Feature Scaling\r\n","\"\"\"from sklearn.preprocessing import StandardScaler\r\n","sc_X = StandardScaler()\r\n","X_train = sc_X.fit_transform(X_train)\r\n","X_test = sc_X.transform(X_test)\r\n","sc_y = StandardScaler()\r\n","y_train = sc_y.fit_transform(y_train)\"\"\"\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'from sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train)\\nX_test = sc_X.transform(X_test)\\nsc_y = StandardScaler()\\ny_train = sc_y.fit_transform(y_train)'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nteIBfjLyD6u","executionInfo":{"status":"ok","timestamp":1613417021890,"user_tz":360,"elapsed":517,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"aa2f0f50-09e1-4306-d8c5-b934d70cfd1f"},"source":["# Fitting Simple Linear Regression to the Training set\r\n","from sklearn.linear_model import LinearRegression\r\n","regressor = LinearRegression()\r\n","regressor.fit(X_train, y_train)\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Yp3SMwu01-9j"},"source":["# Predicting the Test set results\r\n","y_pred = regressor.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":562},"id":"FN3ADxEd4eH2","executionInfo":{"status":"ok","timestamp":1613417037158,"user_tz":360,"elapsed":616,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"f69f9a89-0e3c-401a-e60a-59fbc1565f82"},"source":["import statsmodels.api as sm\r\n","X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis =\r\n","1)\r\n","X_opt = X[:, [0, 1, 2, 3, 4, 5]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.105</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.067</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.758</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Mon, 15 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0737</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>19:23:56</td>     <th>  Log-Likelihood:    </th> <td> -597.88</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1202.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1207.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>  1.94e+04</td> <td>  1.5e+04</td> <td>    1.295</td> <td> 0.202</td> <td>-1.07e+04</td> <td> 4.95e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 4.915e+04</td> <td> 1.63e+04</td> <td>    3.009</td> <td> 0.004</td> <td> 1.63e+04</td> <td>  8.2e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>-2.976e+04</td> <td> 2.49e+04</td> <td>   -1.196</td> <td> 0.238</td> <td>-7.98e+04</td> <td> 2.03e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>-3622.3592</td> <td> 2.19e+04</td> <td>   -0.165</td> <td> 0.869</td> <td>-4.77e+04</td> <td> 4.05e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td> 2.302e+04</td> <td> 9627.153</td> <td>    2.391</td> <td> 0.021</td> <td> 3650.451</td> <td> 4.24e+04</td>\n","</tr>\n","<tr>\n","  <th>x5</th>    <td> 2.302e+04</td> <td> 9627.153</td> <td>    2.391</td> <td> 0.021</td> <td> 3650.451</td> <td> 4.24e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.360</td> <th>  Durbin-Watson:     </th> <td>   0.319</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.835</td> <th>  Jarque-Bera (JB):  </th> <td>   0.030</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 0.026</td> <th>  Prob(JB):          </th> <td>   0.985</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 3.109</td> <th>  Cond. No.          </th> <td>7.71e+17</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.28e-34. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.105\n","Model:                            OLS   Adj. R-squared:                  0.067\n","Method:                 Least Squares   F-statistic:                     2.758\n","Date:                Mon, 15 Feb 2021   Prob (F-statistic):             0.0737\n","Time:                        19:23:56   Log-Likelihood:                -597.88\n","No. Observations:                  50   AIC:                             1202.\n","Df Residuals:                      47   BIC:                             1207.\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const        1.94e+04    1.5e+04      1.295      0.202   -1.07e+04    4.95e+04\n","x1          4.915e+04   1.63e+04      3.009      0.004    1.63e+04     8.2e+04\n","x2         -2.976e+04   2.49e+04     -1.196      0.238   -7.98e+04    2.03e+04\n","x3         -3622.3592   2.19e+04     -0.165      0.869   -4.77e+04    4.05e+04\n","x4          2.302e+04   9627.153      2.391      0.021    3650.451    4.24e+04\n","x5          2.302e+04   9627.153      2.391      0.021    3650.451    4.24e+04\n","==============================================================================\n","Omnibus:                        0.360   Durbin-Watson:                   0.319\n","Prob(Omnibus):                  0.835   Jarque-Bera (JB):                0.030\n","Skew:                           0.026   Prob(JB):                        0.985\n","Kurtosis:                       3.109   Cond. No.                     7.71e+17\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 3.28e-34. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Q7LRNhqA2A_m","colab":{"base_uri":"https://localhost:8080/","height":644},"executionInfo":{"status":"error","timestamp":1613417113571,"user_tz":360,"elapsed":1011,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"92f1ac67-aaa0-4ef5-aa8a-6d2f678c578c"},"source":["# Visualising the Training set results\r\n","plt.scatter(X_train, y_train, color = 'red')\r\n","plt.plot(X_train, regressor.predict(X_train), color = 'blue')\r\n","plt.title('Salary vs Experience (Training set)')\r\n","plt.xlabel('Years of Experience')\r\n","plt.ylabel('Salary')\r\n","plt.show()\r\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-51c9e2ebfde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualising the Training set results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Salary vs Experience (Training set)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Years of Experience'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2816\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must be the same size"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"bz2gXO0z3AYC"},"source":["# Visualising the Test set results\r\n","plt.scatter(X_test, y_test, color = 'red')\r\n","plt.plot(X_train, regressor.predict(X_train), color = 'blue')\r\n","plt.title('Salary vs Experience (Test set)')\r\n","plt.xlabel('Years of Experience')\r\n","plt.ylabel('Salary')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncxuvDBj5J4j"},"source":["# Multiple Linear Regression"]},{"cell_type":"code","metadata":{"id":"rqTxBWht5bXP"},"source":["# Importing the dataset\r\n","dataset = pd.read_csv('50_Startups.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, 4].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBL8PqMB5wN1"},"source":["# Encoding categorical data\r\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n","labelencoder = LabelEncoder()\r\n","X[:, 3] = labelencoder.fit_transform(X[:, 3])\r\n","onehotencoder = OneHotEncoder(categories='auto')\r\n","X = onehotencoder.fit_transform(X).toarray()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jQpWnm355TU"},"source":["# Avoiding the Dummy Variable Trap\r\n","X = X[:, 1:]\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OcbskbER57fG"},"source":["# Splitting the dataset into the Training set and Test set\r\n","from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"uMDf8GkE6Ek1","outputId":"1f6686ff-1ec7-401c-fddb-0b0174f32e5b"},"source":["# Feature Scaling\r\n","\"\"\"from sklearn.preprocessing import StandardScaler\r\n","sc_X = StandardScaler()\r\n","X_train = sc_X.fit_transform(X_train)\r\n","X_test = sc_X.transform(X_test)\r\n","sc_y = StandardScaler()\r\n","y_train = sc_y.fit_transform(y_train)\"\"\"\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'from sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train)\\nX_test = sc_X.transform(X_test)\\nsc_y = StandardScaler()\\ny_train = sc_y.fit_transform(y_train)'"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OctR6cfZ6H1V","executionInfo":{"status":"ok","timestamp":1613418142930,"user_tz":360,"elapsed":667,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"52e9a14d-c894-4f0c-f20d-1fe8e9bb9412"},"source":["# Fitting Multiple Linear Regression to the Training set\r\n","from sklearn.linear_model import LinearRegression\r\n","regressor = LinearRegression()\r\n","regressor.fit(X_train, y_train)\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"j4JMsD7L6KKs"},"source":["# Predicting the Test set results\r\n","y_pred = regressor.predict(X_test)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"4P1W_Wyv6MLQ","executionInfo":{"status":"ok","timestamp":1613418151773,"user_tz":360,"elapsed":743,"user":{"displayName":"FRANZ JOSEF HAIDACHER AVILA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgazkF7P7kolBVKsUvBUBU7DdToblKeYMZL_icC=s64","userId":"05940661152176974124"}},"outputId":"8aaedb09-6896-4013-add9-d057aa540b23"},"source":["# Building the optimal model using Backward Elimination\r\n","import statsmodels.api as sm\r\n","X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\r\n","X_opt = X[:, [0, 1, 2, 3, 4, 5]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n","X_opt = X[:, [0, 1, 3, 4, 5]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n","X_opt = X[:, [0, 3, 4, 5]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n","X_opt = X[:, [0, 3, 5]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n","X_opt = X[:, [0, 3]]\r\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\r\n","regressor_OLS.summary()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.050</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.030</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.532</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Mon, 15 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.118</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>19:42:31</td>     <th>  Log-Likelihood:    </th> <td> -599.37</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1203.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1207.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.133e+05</td> <td> 5670.069</td> <td>   19.980</td> <td> 0.000</td> <td> 1.02e+05</td> <td> 1.25e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> -6.38e+04</td> <td> 4.01e+04</td> <td>   -1.591</td> <td> 0.118</td> <td>-1.44e+05</td> <td> 1.68e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.164</td> <th>  Durbin-Watson:     </th> <td>   0.114</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.921</td> <th>  Jarque-Bera (JB):  </th> <td>   0.001</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 0.009</td> <th>  Prob(JB):          </th> <td>    1.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 2.989</td> <th>  Cond. No.          </th> <td>    7.15</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.050\n","Model:                            OLS   Adj. R-squared:                  0.030\n","Method:                 Least Squares   F-statistic:                     2.532\n","Date:                Mon, 15 Feb 2021   Prob (F-statistic):              0.118\n","Time:                        19:42:31   Log-Likelihood:                -599.37\n","No. Observations:                  50   AIC:                             1203.\n","Df Residuals:                      48   BIC:                             1207.\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.133e+05   5670.069     19.980      0.000    1.02e+05    1.25e+05\n","x1          -6.38e+04   4.01e+04     -1.591      0.118   -1.44e+05    1.68e+04\n","==============================================================================\n","Omnibus:                        0.164   Durbin-Watson:                   0.114\n","Prob(Omnibus):                  0.921   Jarque-Bera (JB):                0.001\n","Skew:                           0.009   Prob(JB):                         1.00\n","Kurtosis:                       2.989   Cond. No.                         7.15\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"vaQ8csk56Ti_"},"source":["# Polynomial Regression"]},{"cell_type":"code","metadata":{"id":"_p7rdJl96_xP"},"source":["# Importing the dataset\r\n","dataset = pd.read_csv('50_Startups.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, 4].values\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0lcJXMq7iet"},"source":["# Encoding categorical data\r\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n","labelencoder = LabelEncoder()\r\n","X[:, 3] = labelencoder.fit_transform(X[:, 3])\r\n","onehotencoder = OneHotEncoder(categories='auto')\r\n","X = onehotencoder.fit_transform(X).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"V3Ra2geZ7VfR","outputId":"0e064722-2513-4ec8-9c2f-514804c006e3"},"source":["# Splitting the dataset into the Training set and Test set\r\n","\"\"\"from sklearn.cross_validation import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\"\"\"\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'from sklearn.cross_validation import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)'"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"mpGaJ94L7XcT","outputId":"fa1107f1-8b7b-4b35-8110-f280c3755612"},"source":["# Feature Scaling\r\n","\"\"\"from sklearn.preprocessing import StandardScaler\r\n","sc_X = StandardScaler()\r\n","X_train = sc_X.fit_transform(X_train)\r\n","X_test = sc_X.transform(X_test)\"\"\"\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'from sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train)\\nX_test = sc_X.transform(X_test)'"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tu1F6kD67Zg9","outputId":"3d6719f9-4be4-4d0d-990c-e91d15d2a79d"},"source":["# Fitting Linear Regression to the dataset\r\n","from sklearn.linear_model import LinearRegression\r\n","lin_reg = LinearRegression()\r\n","lin_reg.fit(X, y)\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"id":"3MnEHZj17la4"},"source":["# Fitting Polynomial Regression to the dataset\r\n","from sklearn.preprocessing import PolynomialFeatures\r\n","poly_reg = PolynomialFeatures(degree = 4)\r\n","X_poly = poly_reg.fit_transform(X)\r\n","poly_reg.fit(X_poly, y)\r\n","lin_reg_2 = LinearRegression()\r\n","lin_reg_2.fit(X_poly, y)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cw1cCRN7qvr"},"source":["# Visualising the Linear Regression results\r\n","plt.scatter(X, y, color = 'red')\r\n","plt.plot(X, lin_reg.predict(X), color = 'blue')\r\n","plt.title('Truth or Bluff (Linear Regression)')\r\n","plt.xlabel('Position level')\r\n","plt.ylabel('Salary')\r\n","plt.show()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOj4r779wP92"},"source":["# **Salary Data**"]},{"cell_type":"markdown","metadata":{"id":"oyJ_pUag8DRh"},"source":["Simple Linear Regression"]},{"cell_type":"code","metadata":{"id":"plrHSRGK1spR"},"source":["# Simple Linear Regression\r\n","\r\n","# Importing the libraries\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","\r\n","# Importing the dataset\r\n","dataset = pd.read_csv('Salary_Data.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, 1].values\r\n","\r\n","# Splitting the dataset into the Training set and Test set\r\n","from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\r\n","\r\n","# Feature Scaling\r\n","\"\"\"from sklearn.preprocessing import StandardScaler\r\n","sc_X = StandardScaler()\r\n","X_train = sc_X.fit_transform(X_train)\r\n","X_test = sc_X.transform(X_test)\r\n","sc_y = StandardScaler()\r\n","y_train = sc_y.fit_transform(y_train)\"\"\"\r\n","\r\n","# Fitting Simple Linear Regression to the Training set\r\n","from sklearn.linear_model import LinearRegression\r\n","regressor = LinearRegression()\r\n","regressor.fit(X_train, y_train)\r\n","\r\n","# Predicting the Test set results\r\n","y_pred = regressor.predict(X_test)\r\n","\r\n","# Visualising the Training set results\r\n","plt.scatter(X_train, y_train, color = 'red')\r\n","plt.plot(X_train, regressor.predict(X_train), color = 'blue')\r\n","plt.title('Salary vs Experience (Training set)')\r\n","plt.xlabel('Years of Experience')\r\n","plt.ylabel('Salary')\r\n","plt.show()\r\n","\r\n","# Visualising the Test set results\r\n","plt.scatter(X_test, y_test, color = 'red')\r\n","plt.plot(X_train, regressor.predict(X_train), color = 'blue')\r\n","plt.title('Salary vs Experience (Test set)')\r\n","plt.xlabel('Years of Experience')\r\n","plt.ylabel('Salary')\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}